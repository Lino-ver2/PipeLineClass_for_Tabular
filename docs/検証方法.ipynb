{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, \\\n",
    "                            recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラスの下に使用例があります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeLine(object):\n",
    "    \"\"\"\n",
    "    __init__ :\n",
    "    アトリビュートで訓練データ、正解データを管理する\n",
    "    （引数）\n",
    "    df: callメソッドでオリジナルのデータが格納される\n",
    "    df_num: callで指定した数値データが格納される。クラスメソッドで上書きされる\n",
    "    df_cat: callで指定したカテゴリデータが格納される\n",
    "    viewer: bool, viewer_row :int 更新後のデータを表示する\n",
    "\n",
    "    __call__ :\n",
    "    インスタンスの生成時に引数でオリジナルデータを渡す\n",
    "    （引数）\n",
    "    data: 使用するオリジナルデータ  (pd.DataFrame\n",
    "    numerical: 数値データのカラム名  (list[str])\n",
    "    categorical: カテゴリデータのカラム名  (list[str])\n",
    "    target: \n",
    "\n",
    "    standard_scaler:\n",
    "    アトリビュートのdf_numを標準化する\n",
    "    （引数）\n",
    "    view: 標準化したdf_numを確認できる\n",
    "\n",
    "    one_hot: \n",
    "    指定したカラムのdf_catをワンホット化してdf_numにconcatする\n",
    "    （引数）\n",
    "    columns: ワンホット化したいカラム名_ \n",
    "    concat: Trueの場合はアトリビュートのself.df_numに連結し更新する\n",
    "    view: ワンホットされたデータがdf_numにconcatされているのを確認できる\n",
    "    return: x_train, x_test, y_train, y_test\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.df: pd.DataFrame = None\n",
    "        self.df_num: pd.DataFrame = None\n",
    "        self.df_cat: pd.DataFrame = None\n",
    "        self.df_target: pd.DataFrame = None\n",
    "        self.viewer = True  # 更新したカラムの表示を切り替え\n",
    "        self.viewer_row = 3  # 表示カラムの行数\n",
    "        self.random_seed = 42  # 乱数シード値\n",
    "\n",
    "    def __call__(self,\n",
    "                 data: pd.DataFrame,\n",
    "                 numerical=['Age', 'Sex', 'RestingBP', 'Cholesterol', \\\n",
    "                 'FastingBS', 'MaxHR', 'ExerciseAngina', 'Oldpeak'],\n",
    "                 categorical=['ChestPainType', 'RestingECG', 'ST_Slope'],\n",
    "                 target=['HeartDisease'],\n",
    "                 train_flg=True\n",
    "                 ) -> pd.DataFrame:\n",
    "\n",
    "        self.df = data\n",
    "        self.df_num = data[numerical]\n",
    "        self.df_cat = data[categorical]\n",
    "        # 正解ラベルが与えられない本番環境では引数からFalseにすること\n",
    "        if train_flg:\n",
    "            self.df_target = data[target]\n",
    "        return self.df_num\n",
    "\n",
    "    def standard_scaler(self):\n",
    "        columns = self.df_num.columns\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.df_num)\n",
    "        self.df_num = scaler.transform(self.df_num)\n",
    "        self.df_num = pd.DataFrame(self.df_num, columns=columns)\n",
    "        if self.viewer:\n",
    "            print('-'*20, '標準化されたdf_num', '-'*20)\n",
    "            display(self.df_num.head(self.viewer_row))\n",
    "        return None\n",
    "\n",
    "    def one_hot(self, columns: list[str], concat=True) -> pd.DataFrame:\n",
    "        one_hotted = pd.get_dummies(self.df_cat[columns])\n",
    "        self.df_num = pd.concat((self.df_num, one_hotted), axis=1)\n",
    "        if self.viewer:\n",
    "            print('-'*20, f'ワンホットされたカラム{columns}', '-'*20)\n",
    "            display(self.df_num.head(self.viewer_row))\n",
    "        return None\n",
    "\n",
    "    def fold_out_split(self, test_size=0.3, to_array=True) -> np.ndarray:\n",
    "        pack = train_test_split(self.df_num,  self.df_target,\n",
    "                                test_size=test_size,\n",
    "                                random_state=self.random_seed)\n",
    "        x_tr, x_te, y_tr, y_te = pack\n",
    "        if to_array:\n",
    "            x_tr, x_te, y_tr, y_te = [i.values for i in pack]\n",
    "            y_tr, y_te = y_tr.reshape(-1), y_te.reshape(-1)\n",
    "        if self.viewer:\n",
    "            print('-'*20, '分割されたデータShape', '-'*20)\n",
    "            print(f'x_train: {x_tr.shape} x_test: {x_te.shape}')\n",
    "            print(f'y_train: {y_tr.shape} y_test: {y_te.shape}')\n",
    "        return x_tr, x_te, y_tr, y_te\n",
    "\n",
    "    def k_fold(self, n_splits=5, to_array=True) -> list[list[np.ndarray]]:\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        packs = []\n",
    "        for train_index, test_index in kf.split(self.df_num):\n",
    "            x_tr, x_te = self.df_num.iloc[train_index], self.df_num.iloc[test_index]\n",
    "            y_tr, y_te = self.df_target.iloc[train_index], self.df_target.iloc[test_index]\n",
    "            pack = (x_tr, x_te,  y_tr, y_te)\n",
    "            if to_array:\n",
    "                pack = [unpack.values for unpack in pack]\n",
    "            packs.append(pack)\n",
    "        if self.viewer: \n",
    "            print(kf.get_n_splits)\n",
    "        return packs\n",
    "\n",
    "    def training(self, valid, Model, valid_args={}, params={}):\n",
    "        if valid == 'fold_out_split':\n",
    "            packs = self.fold_out_split(**valid_args)\n",
    "            model = Model(**params)\n",
    "            model.fit(packs[0], packs[2])\n",
    "            evaluations(model, *packs)\n",
    "            \n",
    "            return model\n",
    "\n",
    "        if valid == 'k_fold':\n",
    "            packs = self.k_fold(**valid_args)\n",
    "            models = []\n",
    "            for i, pack in enumerate(packs):\n",
    "                model = Model(**params)\n",
    "                model.fit(pack[0], pack[2].reshape(-1))\n",
    "                print('-'*20, f'model{i} predict', '-'*20)\n",
    "                evaluations(model, *pack)\n",
    "                models.append(model)\n",
    "            return models\n",
    "\n",
    "\n",
    "\n",
    "# evaluation\n",
    "def evaluations(model, x_train, x_test, y_train, y_test):\n",
    "    evaluate = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "    # 訓練データの評価\n",
    "    train_pred = model.predict(x_train)\n",
    "    train_val = {func.__name__: func(y_train, train_pred) for func in evaluate}\n",
    "    # 検証データの評価\n",
    "    test_pred = model.predict(x_test)\n",
    "    test_val = {func.__name__: func(y_test, test_pred) for func in evaluate}\n",
    "    evals = pd.DataFrame((train_val, test_val), index=['train', 'test'])\n",
    "    display(evals)\n",
    "    return evals\n",
    "\n",
    "\n",
    "def ensemble_prediction(models, x, y):\n",
    "    try:\n",
    "        predict = [model.predict_proba(x) for model in models]\n",
    "        predict_sum = np.sum(predict, axis=0)\n",
    "        ensemble_prediction = np.array(\n",
    "            [np.where(pre[0]<pre[1], 1, 0) for pre in predict_sum]\n",
    "            )\n",
    "    except AttributeError:\n",
    "        print('########## 確率で出力するようパラメータもしくはモデルを設定することを推奨 ############')\n",
    "        predict = [model.predict(x) for model in models]\n",
    "        predict_sum = np.sum(predict, axis=0)\n",
    "        ensemble_prediction = np.array(\n",
    "                [np.where(len(models)//2<=pre, 1, 0) for pre in predict_sum]\n",
    "                )\n",
    "    return ensemble_prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ホールドアウト法を使用する場合\n",
    "PipeLineクラスのtrainingメソッドで valid = 'fold_out_split' を指定する<br>\n",
    "valid_args = {'test_size': テストサイズ比率} を指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.828460</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.779783</td>\n",
       "      <td>0.830769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy_score  precision_score  recall_score  f1_score\n",
       "train        0.828460         0.888889      0.779783  0.830769\n",
       "test         0.775194         0.884058      0.743902  0.807947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')  # パスは確認してください\n",
    "\n",
    "############################# ここを指定する ###################################\n",
    "valid, model = ['fold_out_split', DecisionTreeClassifier]  # 分割数とモデルを指定\n",
    "valid_args = {'test_size': 0.2}  # ホールドアウト法なのでテストサイズの割合を指定\n",
    "params = {'max_depth': 3, }    # 選択したモデルパラメータを入力\n",
    "##############################################################################\n",
    "\n",
    "pipe = PipeLine()\n",
    "pipe.viewer = False\n",
    "pipe(df)\n",
    "# kayano_data = func(pipe.df_num)\n",
    "# pipe.df_num = kayano_data\n",
    "pipe.standard_scaler()\n",
    "pipe.one_hot(['ChestPainType'])\n",
    "models = pipe.training(valid=valid, Model=model, valid_args=valid_args ,params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    "### 交差検証法を使用する場合\n",
    "PipeLineクラスのtrainingメソッドで valid = 'k_fold' を指定する.<br>\n",
    "valid_args = {'n_splits': 分割数} を指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.875244</td>\n",
       "      <td>0.895911</td>\n",
       "      <td>0.870036</td>\n",
       "      <td>0.882784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy_score  precision_score  recall_score  f1_score\n",
       "train        0.875244         0.895911      0.870036  0.882784\n",
       "test         0.844961         0.897436      0.853659  0.875000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "############################# ここを指定する ###################################\n",
    "valid, model = ['fold_out_split', SVC]  # 分割数とモデルを指定\n",
    "valid_args = {'test_size': 0.2}  # ホールドアウト法なのでテストサイズの割合を指定\n",
    "params = {'kernel': 'rbf' ,'probability': True}  # 選択したモデルパラメータを入力\n",
    "##############################################################################\n",
    "\n",
    "pipe = PipeLine()\n",
    "pipe.viewer = False\n",
    "pipe(df)\n",
    "pipe.standard_scaler()\n",
    "pipe.one_hot(['ChestPainType'])\n",
    "models = pipe.training(valid=valid, Model=model, valid_args=valid_args ,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "596b88989fc0dc1fed1e4e461c9c9f08188a37ef0bdca6efc263739311be1bbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
